# CNN-Detection-Of-Eyes-and-Classification


## Introduction to Convolutional Neural Network

In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of artificial neural network (ANN), most commonly applied to analyze visual imagery. CNNs are also known as Shift Invariant or Space Invariant Artificial Neural Networks (SIANN), based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input. They have applications in image and video recognition, recommender systems, image classification, image segmentation, medical image analysis, natural language processing, brain–computer interfaces, and financial time series.

![image](https://user-images.githubusercontent.com/71048405/204509355-913fe849-be78-4b0c-b6b1-3f08ac67d074.png)


CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The "full connectivity" of these networks make them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble patterns of increasing complexity using smaller and simpler patterns embossed in their filters. Therefore, on a scale of connectivity and complexity, CNNs are on the lower extreme.


## The Detection Of Eyes

![image](https://user-images.githubusercontent.com/71048405/204510301-5aaf37b0-c982-4cbc-b9f3-16e85ccdb934.png)

The eyes are the window to the soul. Or so the saying goes. But they’re also a window to a wide range of applications for Computer Vision development. From eye tracking to gaze estimation, eye-focused datasets are powering computer vision applications in a wide range of verticals. Here are a few examples:

>- Virtual and Mixed Reality head-mounted devices rely on eye-gaze estimation to enable efficient rendering and to offer the user realistic interaction with the content. By being able to detect where your gaze is, the VR device can render only that part of the scene thus enabling higher quality for that segment and a more seamless experience. This technique is called foveated rendering and can significantly alleviate the computational and energy burden of VR.
>- Gaze tracking is used in assistive devices for sight-impaired people. Additionally, eye-tracking can help people with motor-impairments interact with computers and can be used to control robotic arms and powered wheelchairs.
>- In commercial contexts, eye tracking and gaze estimation are used to determine engagement with advertisements and content. Eye tracking can be used to provide valuable insight into which features on a web page or in a physical store are the most eye-catching and engaging.
>- Many car manufacturers leverage eye-tracking technology to enhance safety and driver fatigue detection. The ability to classify eye states based on pupil dilation, blink-rate, or eye-closures provides a key metric for detecting drowsiness among drivers. Fatigue causes 20% of car crashes, so the ability to diagnose fatigued drivers and alert them to take a break can save thousands of lives.

The key to developing Computer Vision applications is Data. In this case, large datasets of eyes are the key to continue developing and improving the technologies outlined above.

### Agenda

![image](https://user-images.githubusercontent.com/71048405/204510052-791bb62d-23e2-45d9-8451-ec8b671a6467.png)

### Problem Definition

![image](https://user-images.githubusercontent.com/71048405/204510677-4c47b873-9323-4574-b2c4-f5e94b9eb4c6.png)

### Case Study

![image](https://user-images.githubusercontent.com/71048405/204510837-9b8a162e-2695-4c10-9f0e-1abe8123cd0e.png)

### Pre-Processing

![image](https://user-images.githubusercontent.com/71048405/204511050-89847ba3-b5b7-4a66-81de-5b8b4c248403.png)


### Recomendtion
![image](https://user-images.githubusercontent.com/71048405/204511481-1cad6317-396b-4a0f-b42a-25fdaaafa179.png)

Most of the traditional methods for drowsiness detection are based on behavioral factors, while some require expensive sensors and devices to measure sleepiness and we produced good model With accuracy 97% And made a protype this case study and we can to made a product and will sell It in Egyptian market with low prices

## Team
![image](https://user-images.githubusercontent.com/71048405/204511618-ac6ccb58-a222-470c-80da-6982fcc6eb01.png)
